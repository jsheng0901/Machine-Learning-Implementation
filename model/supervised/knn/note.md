
### 基本原理
参考链接：
- [中文原理讲解](https://blog.csdn.net/chenhepg/article/details/105409153)
- [英文链接图文解释](https://medium.com/swlh/k-nearest-neighbor-ca2593d7a3c4)
- [sklearn中相关应用文档](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
### 优点
- 优化加速过的Knn速度很快。
- 非常容易理解和解释结果和算法过程。
- 对于有稀有类别的数据效果会更好。
- 特别适合多分类问题，当label有多个类别的时候，相比较SVM，LR之类的线性model。
### 缺点
- 需要手动设置参数k，k会随着数据量变化而变化。
- model是lazy learning模式，存储数据量巨大如果不优化的前提下，memory占用多。因为是基于距离的计算，没优化的model遇到维度高数据量大的dataset时候特别慢。
### 知识点提炼
- 参数解释
  - k，选取多少个邻居来决定最终点的label。如何选取K这里需要调参数，cross-validation进行grid search调参，大部分情况下K不能大于样本的平方根。
- 损失函数解释
  - 目标函数是找到最近的点，所以是相似距离，可以是曼哈顿距离，欧氏距离，或者cosine similarity。
- 正则化解释
  - model不适用
- 其它要点 
  - 对于数据需要先标准化/归一化一下，确保不同维度的数据在同一个scale下，否则会出现大维度的数据在距离计算中占比太大，影响结果，所有distance base的model都需要这样提。
  - 优化加速参考KDtree，KBall-tree。不优化的KNN时间复杂度对于一个点来说是O(nd)，空间复杂度是O(nd)，n是总样本数，d是每个样本维度。
### Engineer Work
- 一般来说直接调用sklearn中的KNN包来实现。实际生产中普通版本的KNN目前来说在(100, 4)的数据集上需要1ms左右在8cores/16Memory上。
- 实际工作中，涉及高纬的数据，一般都需要降维，一来是可以克服维度灾难诅咒对于距离计算，二来可以加速，因为distance的计算时间复杂度是O(d)级别。
- 实际工作中KNN一般都是优化过的KDtree版本，详细性能参考KDtree板块。


### 面试问题总结
1. 在k-means或knn，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别。
   - 欧氏距离：最常见的两点之间或多点之间的距离表示法，又称之为欧几里得度量，它定义于欧几里得空间中，欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量量纲）之间的差别等同看待，这一点有时不能满足实际要求。因此，欧氏距离适用于向量各分量的度量标准统一的情况。这也就是为什么对于计算距离的model需要先标准化处理数据，为了所有维度统一scale。
   - 曼哈顿距离：曼哈顿距离，我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和，需要注意的是曼哈顿距离依赖座标系统的转度，而非系统在座标轴上的平移或映射。当坐标轴变动时，点间的距离就会不同。
   - 详细介绍了KNN，距离度量和KD树的[链接](https://blog.csdn.net/v_july_v/article/details/8203674)
2. KNN中的K如何选取的？
   - 本质上是问如何给model调参。
   - 如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；
   - 如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。 
   - K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。
   - 在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。简单点来说就是用cross validation 来调参。